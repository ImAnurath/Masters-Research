{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"6YaKqIfpOnkAwSemb85j\")\n",
    "project = rf.workspace(\"testing-3j1sj\").project(\"data-prep-lsyc8\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the folder for yolov11. However valid folder needs to be change into val by hand.\n",
    "\n",
    "# Define the base directory\n",
    "base_dir = 'data-prep-2' # Change as needed\n",
    "# Step 1: Create new directories for consolidated images and labels\n",
    "new_images_dir = os.path.join(base_dir, 'images')\n",
    "new_labels_dir = os.path.join(base_dir, 'labels')\n",
    "os.makedirs(new_images_dir, exist_ok=True)\n",
    "os.makedirs(new_labels_dir, exist_ok=True)\n",
    "# Define the splits (subfolders)\n",
    "splits = ['train', 'test', 'valid']\n",
    "# Step 2: Copy files from each split into the new structure\n",
    "for split in splits:\n",
    "    # Define the source directories for images and labels\n",
    "    src_images_dir = os.path.join(base_dir, split, 'images')\n",
    "    src_labels_dir = os.path.join(base_dir, split, 'labels')\n",
    "    # Define the destination directories (creating subdirectories named after each split)\n",
    "    dest_images_dir = os.path.join(new_images_dir, split)\n",
    "    dest_labels_dir = os.path.join(new_labels_dir, split)\n",
    "    os.makedirs(dest_images_dir, exist_ok=True)\n",
    "    os.makedirs(dest_labels_dir, exist_ok=True)\n",
    "    # Copy each image file to the corresponding new images subfolder\n",
    "    for file_name in os.listdir(src_images_dir):\n",
    "        src_file = os.path.join(src_images_dir, file_name)\n",
    "        dest_file = os.path.join(dest_images_dir, file_name)\n",
    "        shutil.copy(src_file, dest_file)\n",
    "    # Copy each label file to the corresponding new labels subfolder\n",
    "    for file_name in os.listdir(src_labels_dir):\n",
    "        src_file = os.path.join(src_labels_dir, file_name)\n",
    "        dest_file = os.path.join(dest_labels_dir, file_name)\n",
    "        shutil.copy(src_file, dest_file)\n",
    "\n",
    "print(\"Files copied to new structure successfully.\")\n",
    "# Step 3: Delete the old train, test, and valid folders\n",
    "for split in splits:\n",
    "    folder_path = os.path.join(base_dir, split)\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Deleted folder: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"Folder does not exist: {folder_path}\")\n",
    "\n",
    "print(\"Old folders deleted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() # Free the GPU memory just in case of a problem\n",
    "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True # This one also kind of solves memory issues if there are any but not too reliable.\n",
    "model = YOLO('yolo11m.pt') # Selecting a model. \n",
    "''' All these needs to be trained for around 10 to 15 epochs on the final dataset\n",
    "yolo11n.pt -> Nano\n",
    "yolo11s.pt -> Small\n",
    "yolo11m.pt -> Medium\n",
    "yolo11l.pt -> Large\n",
    "yolo11x.pt -> XL\n",
    "'''\n",
    "\n",
    "results = model.train(\n",
    "    data='/content/data.yaml',  # Path to your data config. Needs adjustment depending on where this is running.\n",
    "    epochs=15,                  # Number of training epochs\n",
    "    imgsz=640,                  # By defaul all the data is 640x640. So this can be left alone.\n",
    "    batch=16,                   # Batch size\n",
    "    device='cuda'               # Set to 0 for GPU, 'cpu' for CPU\n",
    ")\n",
    "''' \n",
    "For the moment rest of the adjustments can be left alone or multiple combinations of various adjustments can be tested in future. \n",
    "Refer to fastai: TODO: Find wtf was that function that combined different hyperparameters. and tested all of them out which then gave you the resul combination.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This part is purely for COLAB, there is no reason to run this on local.\n",
    "'''\n",
    "import locale\n",
    "print(locale.getpreferredencoding())\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "#print(locale.getpreferredencoding)\n",
    "!zip -r /content/runs/detect/train7 /content/runs/detect/train7\n",
    "from google.colab import files  # type: ignore\n",
    "files.download(\"/content/runs/detect/train7.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
